{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import defaultdict\n",
    "from skimage.io import imread\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import xml.etree.ElementTree as ET\n",
    "import cv2\n",
    "\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        resnet = resnet18(pretrained=True)\n",
    "        resnet.avgpool = Identity()\n",
    "        resnet.fc = Identity()\n",
    "\n",
    "        self.downsampling = resnet\n",
    "\n",
    "        self.cat1 = nn.Conv2d(64, 128, 1)\n",
    "        self.cat2 = nn.Conv2d(128, 128, 1)\n",
    "        self.cat3 = nn.Conv2d(256, 128, 1)\n",
    "        \n",
    "        self.upsampling_1 = nn.Sequential(nn.ReLU(),\n",
    "                                          nn.ConvTranspose2d(512, 128, 3, 2, 1, 1)\n",
    "                                         )\n",
    "\n",
    "        self.upsampling_2 = nn.Sequential(nn.ReLU(),\n",
    "                                          nn.BatchNorm2d(256),\n",
    "                                          nn.ConvTranspose2d(256, 128, 3, 2, 1, 1)\n",
    "                                         )\n",
    "\n",
    "        self.upsampling_3 = nn.Sequential(nn.ReLU(),\n",
    "                                          nn.BatchNorm2d(256),\n",
    "                                          nn.ConvTranspose2d(256, 128, 3, 2, 1, 1)\n",
    "                                         )\n",
    "\n",
    "        self.upsampling_4 = nn.Sequential(nn.ReLU(),\n",
    "                                         nn.BatchNorm2d(256),\n",
    "                                         nn.ConvTranspose2d(256, 4, 3, 1, 1) \n",
    "                                        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.downsampling.conv1(x)\n",
    "        x = self.downsampling.bn1(x)\n",
    "        x = self.downsampling.relu(x)\n",
    "        x = self.downsampling.maxpool(x)\n",
    "\n",
    "        down1 = self.downsampling.layer1(x)\n",
    "        cat1 = self.cat1(down1)\n",
    "        down2 = self.downsampling.layer2(down1)\n",
    "        cat2 = self.cat2(down2)\n",
    "        down3 = self.downsampling.layer3(down2)\n",
    "        cat3 = self.cat3(down3)\n",
    "        down4 = self.downsampling.layer4(down3)  \n",
    "\n",
    "        up1 = self.upsampling_1(down4)\n",
    "        up2 = self.upsampling_2(torch.cat((up1, cat3), 1))\n",
    "        up3 = self.upsampling_3(torch.cat((up2, cat2), 1))\n",
    "        up4 = self.upsampling_4(torch.cat((up3, cat1), 1))\n",
    "        \n",
    "        return up4       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert xml to csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_folder_path = 'dataset/xml/'\n",
    "csv_path = 'dataset/labels.csv'\n",
    "img_path = 'dataset/images/'\n",
    "\n",
    "with open(csv_path, 'w') as csvfile:\n",
    "    fieldnames = ['image_name', 'part_name', 'center_x', 'center_y']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    for xml_name in os.listdir(xml_folder_path):\n",
    "        xml_path = xml_folder_path + xml_name\n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        img_name = root.find('filename').text\n",
    "        objects = root.findall('object')\n",
    "\n",
    "        for part in objects:\n",
    "            name = part.find('name').text\n",
    "            object_bb = part.find('bndbox')\n",
    "            xmin = int(object_bb.find('xmin').text)\n",
    "            xmax = int(object_bb.find('xmax').text)\n",
    "            ymin = int(object_bb.find('ymin').text)\n",
    "            ymax = int(object_bb.find('ymax').text)\n",
    "\n",
    "            center_x = (xmin+xmax) // 2\n",
    "            center_y = (ymin+ymax) // 2\n",
    "\n",
    "            writer.writerow({'image_name': img_name, 'part_name': name,\n",
    "                             'center_x': center_x, 'center_y': center_y})            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class detection_dataset(Dataset):\n",
    "    def __init__(self, img_size, img_folder_path, csv_path, transform=True):\n",
    "        self.height = img_size[0]\n",
    "        self.width = img_size[1]\n",
    "        self.folder_path = img_folder_path\n",
    "        self.img_files = os.listdir(img_folder_path)\n",
    "        self.csv_path = csv_path\n",
    "        self.transform = transform\n",
    "        self.get_annotations()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (len(self.img_files))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_name = self.img_files[index]\n",
    "        img = imread(self.folder_path + img_name)\n",
    "        annotation = self.annotations[img_name]\n",
    "        annotation = annotation[:,::4,::4]\n",
    "        if self.transform:\n",
    "            img = img.transpose((2,0,1))\n",
    "            img, annotation = torch.from_numpy(img), torch.from_numpy(annotation)\n",
    "            img = img.type(torch.FloatTensor)\n",
    "            annotation = annotation.type(torch.FloatTensor)\n",
    "        sample = {'image':img, 'annotation':annotation}\n",
    "\n",
    "        return sample\n",
    "          \n",
    "    def get_annotations(self):\n",
    "        self.annotations = defaultdict(lambda: np.zeros([4, self.height, self.width]))\n",
    "        part_mapping = {'Head':0, 'Foot':1, 'Hand':2, 'Trunk':3}\n",
    "        with open(self.csv_path) as csvfile:\n",
    "            readCSV = csv.reader(csvfile)\n",
    "            for row in readCSV:\n",
    "                img_name = row[0]\n",
    "                image_annotation = self.annotations[img_name]\n",
    "                channel = part_mapping[row[1].capitalize()]\n",
    "                x = int(row[3])\n",
    "                y = int(row[2])\n",
    "                \n",
    "                if image_annotation[channel, x-8:x+8, y-8:y+8].shape != (16,16): continue\n",
    "                image_annotation[channel, x-8:x+8, y-8:y+8] = makeGaussian(16,8)\n",
    "                \n",
    "\n",
    "def makeGaussian(size, fwhm = 3):\n",
    "    ''' \n",
    "    Input: size: length of a side of the square\n",
    "           fwhm: full-width-half-maximum (effective radius)\n",
    "    Output: a square gaussian kernel\n",
    "    Reference: https://stackoverflow.com/a/14525830\n",
    "    '''\n",
    "\n",
    "    x = np.arange(0, size, 1, float)\n",
    "    y = x[:,np.newaxis]\n",
    "\n",
    "    x0 = y0 = size // 2\n",
    "\n",
    "    return np.exp(-4*np.log(2) * ((x-x0)**2 + (y-y0)**2) / fwhm**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 188.00 MiB (GPU 0; 3.95 GiB total capacity; 3.25 GiB already allocated; 161.19 MiB free; 45.28 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-bd3059664920>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'annotation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/local/labvision/pandey/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-914fcdd64cf9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mup1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsampling_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdown4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mup2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsampling_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mup1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mup3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsampling_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mup2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mup4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsampling_4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mup3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/local/labvision/pandey/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/local/labvision/pandey/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/local/labvision/pandey/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/local/labvision/pandey/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, output_size)\u001b[0m\n\u001b[1;32m    794\u001b[0m         return F.conv_transpose2d(\n\u001b[1;32m    795\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m             output_padding, self.groups, self.dilation)\n\u001b[0m\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 188.00 MiB (GPU 0; 3.95 GiB total capacity; 3.25 GiB already allocated; 161.19 MiB free; 45.28 MiB cached)"
     ]
    }
   ],
   "source": [
    "# train only the decoder weights for 50 epochs \n",
    "csv_path = 'dataset/labels.csv'\n",
    "img_path = 'dataset/images/'\n",
    "\n",
    "dg = detection_dataset((640,480), img_path, csv_path)\n",
    "dataloader = DataLoader(dg, batch_size=20, shuffle=True)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "model = Model()\n",
    "\n",
    "trainable_parameters = [list(model.upsampling_1.parameters()) +\\\n",
    "                        list(model.upsampling_2.parameters()) +\\\n",
    "                        list(model.upsampling_3.parameters()) +\\\n",
    "                        list(model.upsampling_4.parameters())]\n",
    "optimizer = Adam(model.parameters())\n",
    "#optimizer = Adam(trainable_parameters)\n",
    "model.cuda()\n",
    "criterion.cuda()\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for data in dataloader:\n",
    "        img, bb = data['image'], data['annotation']\n",
    "        img, bb = img.cuda(), bb.cuda()   \n",
    "        pred = model(img)   \n",
    "        loss = criterion(pred, bb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # calculate precision and false error percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the entire model for 50 more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters())\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for data in dataloader:\n",
    "        img, bb = data['image'], data['annotation']\n",
    "        img, bb = img.cuda(), bb.cuda()   \n",
    "        pred = model(img)   \n",
    "        loss = criterion(pred, bb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_network_output(out):\n",
    "    head = out(..., 0) * 255\n",
    "    foot = out(..., 1) * 255\n",
    "    hands = out(..., 2) * 255\n",
    "    trunk = out(..., 3) * 255\n",
    "    \n",
    "    blurred_head = cv2.GaussianBlur(head, (5, 5), 0)\n",
    "    blurred_foot = cv2.GaussianBlur(foot, (5,5), 0)\n",
    "    blurred_hands = cv2.GaussianBlur(hands, (5,5), 0)\n",
    "    blurred_trunk = cv2.GaussianBlur(trunk, (5,5), 0)\n",
    "    \n",
    "    thresh_head = cv2.threshold(blurred_head, 60, 255, cv2.THRESH_BINARY)[1]\n",
    "    thresh_foot = cv2.threshold(blurred_head, 60, 255, cv2.THRESH_BINARY)[1]\n",
    "    thresh_hands = cv2.threshold(blurred_head, 60, 255, cv2.THRESH_BINARY)[1]\n",
    "    thresh_trunk = cv2.threshold(blurred_head, 60, 255, cv2.THRESH_BINARY)[1]\n",
    "    \n",
    "    cnts_head = cv2.findContours(thresh_head.copy(), cv2.RETR_EXTERNAL,\n",
    "           cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts_head = imutils.grab_contours(cnts_head)\n",
    "    \n",
    "    cnts_foot = cv2.findContours(thresh_foot.copy(), cv2.RETR_EXTERNAL,\n",
    "           cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts_foot = imutils.grab_contours(cnts_foot)\n",
    "    \n",
    "    cnts_hands = cv2.findContours(thresh_hands.copy(), cv2.RETR_EXTERNAL,\n",
    "           cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts_hands = imutils.grab_contours(cnts_hands)\n",
    "    \n",
    "    cnts_trunk = cv2.findContours(thresh_trunk.copy(), cv2.RETR_EXTERNAL,\n",
    "           cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts_trunk = imutils.grab_contours(cnts_trunk)  \n",
    "    \n",
    "    heads = []\n",
    "    foot = []\n",
    "    hands = []\n",
    "    trunk = []\n",
    "    \n",
    "    for c in cnts_head:\n",
    "        M = cv2.moments(c)\n",
    "        c_x = int(M[\"m10\"] / M[\"m00\"])\n",
    "        c_y = int(M[\"m01\"] / M[\"m00\"])\n",
    "        heads.append([c_x, c_y])\n",
    "        \n",
    "    for c in cnts_foot:\n",
    "        M = cv2.moments(c)\n",
    "        c_x = int(M[\"m10\"] / M[\"m00\"])\n",
    "        c_y = int(M[\"m01\"] / M[\"m00\"])\n",
    "        foot.append([c_x, x_y])\n",
    "        \n",
    "    for c in cnts_hands:\n",
    "        M = cv2.moments(c)\n",
    "        c_x = int(M[\"m10\"] / M[\"m00\"])\n",
    "        c_y = int(M[\"m01\"] / M[\"m00\"])\n",
    "        hands.append([c_x, x_y])\n",
    "        \n",
    "    for c in cnts_trunk:\n",
    "        M = cv2.moments(c)\n",
    "        c_x = int(M[\"m10\"] / M[\"m00\"])\n",
    "        c_y = int(M[\"m01\"] / M[\"m00\"])        \n",
    "        trunk.append([c_x, x_y])\n",
    "        \n",
    "    return [heads, foot, hands, trunk]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
