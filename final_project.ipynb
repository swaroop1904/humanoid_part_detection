{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models import resnet18\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import defaultdict\n",
    "from skimage.io import imread\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        resnet = resnet18(pretrained=True)\n",
    "        resnet.avgpool = Identity()\n",
    "        resnet.fc = Identity()\n",
    "\n",
    "        self.downsampling = resnet\n",
    "\n",
    "        self.cat1 = nn.Conv2d(64, 128, 1)\n",
    "        self.cat2 = nn.Conv2d(128, 128, 1)\n",
    "        self.cat3 = nn.Conv2d(256, 128, 1)\n",
    "        \n",
    "        self.upsampling_1 = nn.Sequential(nn.ReLU(),\n",
    "                                          nn.ConvTranspose2d(512, 128, 3, 2, 1, 1)\n",
    "                                         )\n",
    "\n",
    "        self.upsampling_2 = nn.Sequential(nn.ReLU(),\n",
    "                                          nn.BatchNorm2d(256),\n",
    "                                          nn.ConvTranspose2d(256, 128, 3, 2, 1, 1)\n",
    "                                         )\n",
    "\n",
    "        self.upsampling_3 = nn.Sequential(nn.ReLU(),\n",
    "                                          nn.BatchNorm2d(256),\n",
    "                                          nn.ConvTranspose2d(256, 128, 3, 2, 1, 1)\n",
    "                                         )\n",
    "\n",
    "        self.upsampling_4 = nn.Sequential(nn.ReLU(),\n",
    "                                         nn.BatchNorm2d(256),\n",
    "                                         nn.ConvTranspose2d(256, 4, 3, 1, 1) \n",
    "                                        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.downsampling.conv1(x)\n",
    "        x = self.downsampling.bn1(x)\n",
    "        x = self.downsampling.relu(x)\n",
    "        x = self.downsampling.maxpool(x)\n",
    "\n",
    "        down1 = self.downsampling.layer1(x)\n",
    "        cat1 = self.cat1(down1)\n",
    "        down2 = self.downsampling.layer2(down1)\n",
    "        cat2 = self.cat2(down2)\n",
    "        down3 = self.downsampling.layer3(down2)\n",
    "        cat3 = self.cat3(down3)\n",
    "        down4 = self.downsampling.layer4(down3)  \n",
    "\n",
    "        up1 = self.upsampling_1(down4)\n",
    "        up2 = self.upsampling_2(torch.cat((up1, cat3), 1))\n",
    "        up3 = self.upsampling_3(torch.cat((up2, cat2), 1))\n",
    "        up4 = self.upsampling_4(torch.cat((up3, cat1), 1))\n",
    "        \n",
    "        return up4       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert xml to csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_folder_path = 'dataset/drive-download-20190813T171752Z-001/xml/'\n",
    "csv_path = 'dataset/drive-download-20190813T171752Z-001/labels.csv'\n",
    "img_path = 'dataset/drive-download-20190813T171752Z-001/xml/images/'\n",
    "\n",
    "with open(csv_path, 'w') as csvfile:\n",
    "    fieldnames = ['image_name', 'part_name', 'center_x', 'center_y']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    for xml_name in os.listdir(xml_folder_path):\n",
    "        xml_path = xml_folder_path + xml_name\n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        img_name = root.find('filename').text\n",
    "        objects = root.findall('object')\n",
    "\n",
    "        for part in objects:\n",
    "            name = part.find('name').text\n",
    "            object_bb = part.find('bndbox')\n",
    "            xmin = int(object_bb.find('xmin').text)\n",
    "            xmax = int(object_bb.find('xmax').text)\n",
    "            ymin = int(object_bb.find('ymin').text)\n",
    "            ymax = int(object_bb.find('ymax').text)\n",
    "\n",
    "            center_x = (xmin+xmax) // 2\n",
    "            center_y = (ymin+ymax) // 2\n",
    "\n",
    "            writer.writerow({'image_name': img_name, 'part_name': name,\n",
    "                             'center_x': center_x, 'center_y': center_y})            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class detection_dataset(Dataset):\n",
    "    def __init__(self, img_size, img_folder_path, csv_path, transform=True):\n",
    "        self.height = img_size[0]\n",
    "        self.width = img_size[1]\n",
    "        self.folder_path = img_folder_path\n",
    "        self.img_files = os.listdir(img_folder_path)\n",
    "        self.csv_path = csv_path\n",
    "        self.transform = transform\n",
    "        self.get_annotations()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (len(self.img_files))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_name = self.img_files[index]\n",
    "        img = imread(self.folder_path + img_name)\n",
    "        annotation = self.annotations[img_name]\n",
    "        \n",
    "        if self.transform:\n",
    "            img, annotation = torch.from_numpy(img), torch.from_numpy(annotation)\n",
    "\n",
    "        img = img.type(torch.FloatTensor)\n",
    "        annotation = annotation.type(torch.FloatTensor)\n",
    "        sample = {'image':img, 'annotation':annotation}\n",
    "\n",
    "        return sample\n",
    "          \n",
    "    def get_annotations(self):\n",
    "        self.annotations = defaultdict(lambda: np.zeros([4, self.height, self.width]))\n",
    "        part_mapping = {'Head':0, 'Foot':1, 'Hand':2, 'Trunk':3}\n",
    "        with open(self.csv_path) as csvfile:\n",
    "            readCSV = csv.reader(csvfile)\n",
    "            for row in readCSV:\n",
    "                img_name = row[0]\n",
    "                image_annotation = self.annotations[img_name]\n",
    "                channel = part_mapping[row[1].capitalize()]\n",
    "                # change this to be gaussian\n",
    "                x = int(row[3])\n",
    "                y = int(row[2])\n",
    "                image_annotation[channel, x-8:x+8, y-8:y+8] = makeGaussian(16,8)\n",
    "\n",
    "def makeGaussian(size, fwhm = 3, center=None):\n",
    "    \"\"\" Make a square gaussian kernel.\n",
    "\n",
    "    size is the length of a side of the square\n",
    "    fwhm is full-width-half-maximum, which\n",
    "    can be thought of as an effective radius.\n",
    "    \n",
    "    Reference: https://stackoverflow.com/a/14525830\n",
    "    \"\"\"\n",
    "\n",
    "    x = np.arange(0, size, 1, float)\n",
    "    y = x[:,np.newaxis]\n",
    "\n",
    "    x0 = y0 = size // 2\n",
    "\n",
    "    return np.exp(-4*np.log(2) * ((x-x0)**2 + (y-y0)**2) / fwhm**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'dataset/drive-download-20190813T171752Z-001/images/'\n",
    "csv_path = 'dataset/drive-download-20190813T171752Z-001/labels.csv'\n",
    "\n",
    "dg = detection_dataset((700,700), img_path, csv_path)\n",
    "dataloader = DataLoader(dg, batch_size=20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "model = Model()\n",
    "optimizer = Adam(model.parameters())\n",
    "\n",
    "model.cuda()\n",
    "criterion.cuda()\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for data in dataloader:\n",
    "        img, bb = data['image'], data['annotation']\n",
    "        img, bb = img.cuda(), bb.cuda()   \n",
    "        pred = model(img)   \n",
    "        loss = criterion(pred, bb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # calculate precision and false error percentage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 16)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# precision\n",
    "# false error rate\n",
    "\n",
    "annotation = np.zeros([4,100,100])\n",
    "annotation[0, 10-8:10+8, 10-8:10+8].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25, 0.29, 0.34, 0.38, 0.42, 0.45, 0.48, 0.49, 0.5 , 0.49, 0.48,\n",
       "        0.45, 0.42, 0.38, 0.34, 0.29],\n",
       "       [0.29, 0.35, 0.4 , 0.45, 0.49, 0.53, 0.56, 0.58, 0.59, 0.58, 0.56,\n",
       "        0.53, 0.49, 0.45, 0.4 , 0.35],\n",
       "       [0.34, 0.4 , 0.46, 0.52, 0.57, 0.61, 0.65, 0.67, 0.68, 0.67, 0.65,\n",
       "        0.61, 0.57, 0.52, 0.46, 0.4 ],\n",
       "       [0.38, 0.45, 0.52, 0.58, 0.64, 0.69, 0.73, 0.75, 0.76, 0.75, 0.73,\n",
       "        0.69, 0.64, 0.58, 0.52, 0.45],\n",
       "       [0.42, 0.49, 0.57, 0.64, 0.71, 0.76, 0.81, 0.83, 0.84, 0.83, 0.81,\n",
       "        0.76, 0.71, 0.64, 0.57, 0.49],\n",
       "       [0.45, 0.53, 0.61, 0.69, 0.76, 0.82, 0.87, 0.9 , 0.91, 0.9 , 0.87,\n",
       "        0.82, 0.76, 0.69, 0.61, 0.53],\n",
       "       [0.48, 0.56, 0.65, 0.73, 0.81, 0.87, 0.92, 0.95, 0.96, 0.95, 0.92,\n",
       "        0.87, 0.81, 0.73, 0.65, 0.56],\n",
       "       [0.49, 0.58, 0.67, 0.75, 0.83, 0.9 , 0.95, 0.98, 0.99, 0.98, 0.95,\n",
       "        0.9 , 0.83, 0.75, 0.67, 0.58],\n",
       "       [0.5 , 0.59, 0.68, 0.76, 0.84, 0.91, 0.96, 0.99, 1.  , 0.99, 0.96,\n",
       "        0.91, 0.84, 0.76, 0.68, 0.59],\n",
       "       [0.49, 0.58, 0.67, 0.75, 0.83, 0.9 , 0.95, 0.98, 0.99, 0.98, 0.95,\n",
       "        0.9 , 0.83, 0.75, 0.67, 0.58],\n",
       "       [0.48, 0.56, 0.65, 0.73, 0.81, 0.87, 0.92, 0.95, 0.96, 0.95, 0.92,\n",
       "        0.87, 0.81, 0.73, 0.65, 0.56],\n",
       "       [0.45, 0.53, 0.61, 0.69, 0.76, 0.82, 0.87, 0.9 , 0.91, 0.9 , 0.87,\n",
       "        0.82, 0.76, 0.69, 0.61, 0.53],\n",
       "       [0.42, 0.49, 0.57, 0.64, 0.71, 0.76, 0.81, 0.83, 0.84, 0.83, 0.81,\n",
       "        0.76, 0.71, 0.64, 0.57, 0.49],\n",
       "       [0.38, 0.45, 0.52, 0.58, 0.64, 0.69, 0.73, 0.75, 0.76, 0.75, 0.73,\n",
       "        0.69, 0.64, 0.58, 0.52, 0.45],\n",
       "       [0.34, 0.4 , 0.46, 0.52, 0.57, 0.61, 0.65, 0.67, 0.68, 0.67, 0.65,\n",
       "        0.61, 0.57, 0.52, 0.46, 0.4 ],\n",
       "       [0.29, 0.35, 0.4 , 0.45, 0.49, 0.53, 0.56, 0.58, 0.59, 0.58, 0.56,\n",
       "        0.53, 0.49, 0.45, 0.4 , 0.35]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def makeGaussian(size, fwhm = 3, center=None):\n",
    "    \"\"\" Make a square gaussian kernel.\n",
    "\n",
    "    size is the length of a side of the square\n",
    "    fwhm is full-width-half-maximum, which\n",
    "    can be thought of as an effective radius.\n",
    "    \n",
    "    Taken from https://stackoverflow.com/a/14525830\n",
    "    \"\"\"\n",
    "\n",
    "    x = np.arange(0, size, 1, float)\n",
    "    y = x[:,np.newaxis]\n",
    "\n",
    "    if center is None:\n",
    "        x0 = y0 = size // 2\n",
    "    else:\n",
    "        x0 = center[0]\n",
    "        y0 = center[1]\n",
    "\n",
    "    return np.exp(-4*np.log(2) * ((x-x0)**2 + (y-y0)**2) / fwhm**2)\n",
    "\n",
    "out = makeGaussian(16,16)\n",
    "np.around(out,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25, 0.34, 0.42, 0.48, 0.5 , 0.48, 0.42, 0.34],\n",
       "       [0.34, 0.46, 0.57, 0.65, 0.68, 0.65, 0.57, 0.46],\n",
       "       [0.42, 0.57, 0.71, 0.81, 0.84, 0.81, 0.71, 0.57],\n",
       "       [0.48, 0.65, 0.81, 0.92, 0.96, 0.92, 0.81, 0.65],\n",
       "       [0.5 , 0.68, 0.84, 0.96, 1.  , 0.96, 0.84, 0.68],\n",
       "       [0.48, 0.65, 0.81, 0.92, 0.96, 0.92, 0.81, 0.65],\n",
       "       [0.42, 0.57, 0.71, 0.81, 0.84, 0.81, 0.71, 0.57],\n",
       "       [0.34, 0.46, 0.57, 0.65, 0.68, 0.65, 0.57, 0.46]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
