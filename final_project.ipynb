{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models import resnet18\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import defaultdict\n",
    "from skimage.io import imread\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import xml.etree.ElementTree as ET\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        resnet = resnet18(pretrained=True)\n",
    "        resnet.avgpool = Identity()\n",
    "        resnet.fc = Identity()\n",
    "\n",
    "        self.downsampling = resnet\n",
    "\n",
    "        self.cat1 = nn.Conv2d(64, 128, 1)\n",
    "        self.cat2 = nn.Conv2d(128, 128, 1)\n",
    "        self.cat3 = nn.Conv2d(256, 128, 1)\n",
    "        \n",
    "        self.upsampling_1 = nn.Sequential(nn.ReLU(),\n",
    "                                          nn.ConvTranspose2d(512, 128, 3, 2, 1, 1)\n",
    "                                         )\n",
    "\n",
    "        self.upsampling_2 = nn.Sequential(nn.ReLU(),\n",
    "                                          nn.BatchNorm2d(256),\n",
    "                                          nn.ConvTranspose2d(256, 128, 3, 2, 1, 1)\n",
    "                                         )\n",
    "\n",
    "        self.upsampling_3 = nn.Sequential(nn.ReLU(),\n",
    "                                          nn.BatchNorm2d(256),\n",
    "                                          nn.ConvTranspose2d(256, 128, 3, 2, 1, 1)\n",
    "                                         )\n",
    "\n",
    "        self.upsampling_4 = nn.Sequential(nn.ReLU(),\n",
    "                                         nn.BatchNorm2d(256),\n",
    "                                         nn.ConvTranspose2d(256, 4, 3, 1, 1) \n",
    "                                        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.downsampling.conv1(x)\n",
    "        x = self.downsampling.bn1(x)\n",
    "        x = self.downsampling.relu(x)\n",
    "        x = self.downsampling.maxpool(x)\n",
    "\n",
    "        down1 = self.downsampling.layer1(x)\n",
    "        cat1 = self.cat1(down1)\n",
    "        down2 = self.downsampling.layer2(down1)\n",
    "        cat2 = self.cat2(down2)\n",
    "        down3 = self.downsampling.layer3(down2)\n",
    "        cat3 = self.cat3(down3)\n",
    "        down4 = self.downsampling.layer4(down3)  \n",
    "\n",
    "        up1 = self.upsampling_1(down4)\n",
    "        up2 = self.upsampling_2(torch.cat((up1, cat3), 1))\n",
    "        up3 = self.upsampling_3(torch.cat((up2, cat2), 1))\n",
    "        up4 = self.upsampling_4(torch.cat((up3, cat1), 1))\n",
    "        \n",
    "        return up4       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert xml to csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_folder_path = 'dataset/drive-download-20190813T171752Z-001/xml/'\n",
    "csv_path = 'dataset/drive-download-20190813T171752Z-001/labels.csv'\n",
    "img_path = 'dataset/drive-download-20190813T171752Z-001/xml/images/'\n",
    "\n",
    "with open(csv_path, 'w') as csvfile:\n",
    "    fieldnames = ['image_name', 'part_name', 'center_x', 'center_y']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    for xml_name in os.listdir(xml_folder_path):\n",
    "        xml_path = xml_folder_path + xml_name\n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        img_name = root.find('filename').text\n",
    "        objects = root.findall('object')\n",
    "\n",
    "        for part in objects:\n",
    "            name = part.find('name').text\n",
    "            object_bb = part.find('bndbox')\n",
    "            xmin = int(object_bb.find('xmin').text)\n",
    "            xmax = int(object_bb.find('xmax').text)\n",
    "            ymin = int(object_bb.find('ymin').text)\n",
    "            ymax = int(object_bb.find('ymax').text)\n",
    "\n",
    "            center_x = (xmin+xmax) // 2\n",
    "            center_y = (ymin+ymax) // 2\n",
    "\n",
    "            writer.writerow({'image_name': img_name, 'part_name': name,\n",
    "                             'center_x': center_x, 'center_y': center_y})            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class detection_dataset(Dataset):\n",
    "    def __init__(self, img_size, img_folder_path, csv_path, transform=True):\n",
    "        self.height = img_size[0]\n",
    "        self.width = img_size[1]\n",
    "        self.folder_path = img_folder_path\n",
    "        self.img_files = os.listdir(img_folder_path)\n",
    "        self.csv_path = csv_path\n",
    "        self.transform = transform\n",
    "        self.get_annotations()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (len(self.img_files))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_name = self.img_files[index]\n",
    "        img = imread(self.folder_path + img_name)\n",
    "        annotation = self.annotations[img_name]\n",
    "        \n",
    "        if self.transform:\n",
    "            img, annotation = torch.from_numpy(img), torch.from_numpy(annotation)\n",
    "\n",
    "        img = img.type(torch.FloatTensor)\n",
    "        annotation = annotation.type(torch.FloatTensor)\n",
    "        sample = {'image':img, 'annotation':annotation}\n",
    "\n",
    "        return sample\n",
    "          \n",
    "    def get_annotations(self):\n",
    "        self.annotations = defaultdict(lambda: np.zeros([4, self.height, self.width]))\n",
    "        part_mapping = {'Head':0, 'Foot':1, 'Hand':2, 'Trunk':3}\n",
    "        with open(self.csv_path) as csvfile:\n",
    "            readCSV = csv.reader(csvfile)\n",
    "            for row in readCSV:\n",
    "                img_name = row[0]\n",
    "                image_annotation = self.annotations[img_name]\n",
    "                channel = part_mapping[row[1].capitalize()]\n",
    "                # change this to be gaussian\n",
    "                x = int(row[3])\n",
    "                y = int(row[2])\n",
    "                image_annotation[channel, x-8:x+8, y-8:y+8] = makeGaussian(16,8)\n",
    "\n",
    "def makeGaussian(size, fwhm = 3):\n",
    "    ''' \n",
    "    Input: size: length of a side of the square\n",
    "           fwhm: full-width-half-maximum (effective radius)\n",
    "    Output: a square gaussian kernel\n",
    "    Reference: https://stackoverflow.com/a/14525830\n",
    "    '''\n",
    "\n",
    "    x = np.arange(0, size, 1, float)\n",
    "    y = x[:,np.newaxis]\n",
    "\n",
    "    x0 = y0 = size // 2\n",
    "\n",
    "    return np.exp(-4*np.log(2) * ((x-x0)**2 + (y-y0)**2) / fwhm**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'dataset/drive-download-20190813T171752Z-001/images/'\n",
    "csv_path = 'dataset/drive-download-20190813T171752Z-001/labels.csv'\n",
    "\n",
    "dg = detection_dataset((700,700), img_path, csv_path)\n",
    "dataloader = DataLoader(dg, batch_size=20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "model = Model()\n",
    "optimizer = Adam(model.parameters())\n",
    "\n",
    "model.cuda()\n",
    "criterion.cuda()\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for data in dataloader:\n",
    "        img, bb = data['image'], data['annotation']\n",
    "        img, bb = img.cuda(), bb.cuda()   \n",
    "        pred = model(img)   \n",
    "        loss = criterion(pred, bb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # calculate precision and false error percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_network_output(out):\n",
    "    head = out(..., 0) * 255\n",
    "    foot = out(..., 1) * 255\n",
    "    hands = out(..., 2) * 255\n",
    "    trunk = out(..., 3) * 255\n",
    "    \n",
    "    blurred_head = cv2.GaussianBlur(head, (5, 5), 0)\n",
    "    blurred_foot = cv2.GaussianBlur(foot, (5,5), 0)\n",
    "    blurred_hands = cv2.GaussianBlur(hands, (5,5), 0)\n",
    "    blurred_trunk = cv2.GaussianBlur(trunk, (5,5), 0)\n",
    "    \n",
    "    thresh_head = cv2.threshold(blurred_head, 60, 255, cv2.THRESH_BINARY)[1]\n",
    "    thresh_foot = cv2.threshold(blurred_head, 60, 255, cv2.THRESH_BINARY)[1]\n",
    "    thresh_hands = cv2.threshold(blurred_head, 60, 255, cv2.THRESH_BINARY)[1]\n",
    "    thresh_trunk = cv2.threshold(blurred_head, 60, 255, cv2.THRESH_BINARY)[1]\n",
    "    \n",
    "    cnts_head = cv2.findContours(thresh_head.copy(), cv2.RETR_EXTERNAL,\n",
    "           cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts_head = imutils.grab_contours(cnts_head)\n",
    "    \n",
    "    cnts_foot = cv2.findContours(thresh_foot.copy(), cv2.RETR_EXTERNAL,\n",
    "           cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts_foot = imutils.grab_contours(cnts_foot)\n",
    "    \n",
    "    cnts_hands = cv2.findContours(thresh_hands.copy(), cv2.RETR_EXTERNAL,\n",
    "           cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts_hands = imutils.grab_contours(cnts_hands)\n",
    "    \n",
    "    cnts_trunk = cv2.findContours(thresh_trunk.copy(), cv2.RETR_EXTERNAL,\n",
    "           cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts_trunk = imutils.grab_contours(cnts_trunk)  \n",
    "    \n",
    "    heads = []\n",
    "    foot = []\n",
    "    hands = []\n",
    "    trunk = []\n",
    "    \n",
    "    for c in cnts_head:\n",
    "        M = cv2.moments(c)\n",
    "        c_x = int(M[\"m10\"] / M[\"m00\"])\n",
    "        c_y = int(M[\"m01\"] / M[\"m00\"])\n",
    "        heads.append([c_x, c_y])\n",
    "        \n",
    "    for c in cnts_foot:\n",
    "        M = cv2.moments(c)\n",
    "        c_x = int(M[\"m10\"] / M[\"m00\"])\n",
    "        c_y = int(M[\"m01\"] / M[\"m00\"])\n",
    "        foot.append([c_x, x_y])\n",
    "        \n",
    "    for c in cnts_hands:\n",
    "        M = cv2.moments(c)\n",
    "        c_x = int(M[\"m10\"] / M[\"m00\"])\n",
    "        c_y = int(M[\"m01\"] / M[\"m00\"])\n",
    "        hands.append([c_x, x_y])\n",
    "        \n",
    "    for c in cnts_trunk:\n",
    "        M = cv2.moments(c)\n",
    "        c_x = int(M[\"m10\"] / M[\"m00\"])\n",
    "        c_y = int(M[\"m01\"] / M[\"m00\"])        \n",
    "        trunk.append([c_x, x_y])\n",
    "        \n",
    "    return [heads, foot, hands, trunk]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
